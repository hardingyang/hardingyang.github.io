<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="What is deep learning总结： 如果一个神经网络大于2层，则可以被认为是深度学习，大于10层则是非常深度的学习 人工智能&gt;机器学习&gt;深度学习 Image Fundamentals什么是像素？照片是由万千像素组成的像素网格，一个像素可以认为是一个颜色。 所有颜色可以由三原色组成，灰度值由0-255，是最暗，255最亮 在一个照片中，我们该怎么展示像素？想象一个照片是一个">
<meta property="og:type" content="article">
<meta property="og:title" content="deep learning for computer vision">
<meta property="og:url" content="https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/index.html">
<meta property="og:site_name" content="Jenkooo">
<meta property="og:description" content="What is deep learning总结： 如果一个神经网络大于2层，则可以被认为是深度学习，大于10层则是非常深度的学习 人工智能&gt;机器学习&gt;深度学习 Image Fundamentals什么是像素？照片是由万千像素组成的像素网格，一个像素可以认为是一个颜色。 所有颜色可以由三原色组成，灰度值由0-255，是最暗，255最亮 在一个照片中，我们该怎么展示像素？想象一个照片是一个">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-04-22T14:13:37.571Z">
<meta property="article:modified_time" content="2019-11-01T15:53:16.773Z">
<meta property="article:author" content="Jenkooo">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>deep learning for computer vision</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
      
<link rel="stylesheet" href="/css/rtl.css">

    
    <!-- rss -->
    
    
<meta name="generator" content="Hexo 4.2.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2020/04/22/leetcode%E7%AC%AC157%E5%91%A8%E8%B5%9B%E8%AE%B0%E5%BD%95/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2020/04/22/AntvG2/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/" target="_blank" rel="noopener"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&text=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&title=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&is_video=false&description=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=deep learning for computer vision&body=Check out this article: https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&title=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&title=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&title=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&title=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&name=deep learning for computer vision&description=" target="_blank" rel="noopener"><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://news.ycombinator.com/submitlink?u=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&t=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-is-deep-learning"><span class="toc-number">1.</span> <span class="toc-text">What is deep learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Image-Fundamentals"><span class="toc-number">2.</span> <span class="toc-text">Image Fundamentals</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是像素？"><span class="toc-number">2.1.</span> <span class="toc-text">什么是像素？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#在一个照片中，我们该怎么展示像素？"><span class="toc-number">2.2.</span> <span class="toc-text">在一个照片中，我们该怎么展示像素？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#我们该怎么去接受像素用Numpy库去展示它"><span class="toc-number">2.3.</span> <span class="toc-text">我们该怎么去接受像素用Numpy库去展示它?</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Image-Classification-Basic"><span class="toc-number">3.</span> <span class="toc-text">Image Classification Basic</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是图片分类？"><span class="toc-number">3.1.</span> <span class="toc-text">什么是图片分类？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#深度学习的类型"><span class="toc-number">3.2.</span> <span class="toc-text">深度学习的类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#建立深度学习网络步骤"><span class="toc-number">3.3.</span> <span class="toc-text">建立深度学习网络步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基于特征的学习和深度学习在图片分类的不同"><span class="toc-number">3.4.</span> <span class="toc-text">基于特征的学习和深度学习在图片分类的不同</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Datasets-for-Image-Classification"><span class="toc-number">4.</span> <span class="toc-text">Datasets for Image Classification</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MNIST"><span class="toc-number">4.1.</span> <span class="toc-text">MNIST</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Animals-Dogs-Cats-Pandas"><span class="toc-number">4.2.</span> <span class="toc-text">Animals: Dogs, Cats, Pandas</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CIFAR-10"><span class="toc-number">4.3.</span> <span class="toc-text">CIFAR-10</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SMILES"><span class="toc-number">4.4.</span> <span class="toc-text">SMILES</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kaggle-Dogs-Vs-cats"><span class="toc-number">4.5.</span> <span class="toc-text">Kaggle: Dogs Vs cats</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flowers-17"><span class="toc-number">4.6.</span> <span class="toc-text">Flowers-17</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CALTECH-101"><span class="toc-number">4.7.</span> <span class="toc-text">CALTECH-101</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tiny-ImageNet-200"><span class="toc-number">4.8.</span> <span class="toc-text">Tiny ImageNet 200</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Adience"><span class="toc-number">4.9.</span> <span class="toc-text">Adience</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ImageNet"><span class="toc-number">4.10.</span> <span class="toc-text">ImageNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Indoor-CVPR"><span class="toc-number">4.11.</span> <span class="toc-text">Indoor CVPR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Stanford-Cars"><span class="toc-number">4.12.</span> <span class="toc-text">Stanford Cars</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Your-First-Image-Classifier"><span class="toc-number">5.</span> <span class="toc-text">Your First Image Classifier</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K-NN-Algorithm"><span class="toc-number">5.1.</span> <span class="toc-text">K-NN Algorithm</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Parameterized-Learning"><span class="toc-number">6.</span> <span class="toc-text">Parameterized Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#An-Introduction-to-Linear-Classification"><span class="toc-number">6.1.</span> <span class="toc-text">An Introduction to Linear Classification</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Linear-Classification-From-Images-to-Labels"><span class="toc-number">6.2.</span> <span class="toc-text">Linear Classification: From Images to Labels</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Role-of-Loss-Functions"><span class="toc-number">6.3.</span> <span class="toc-text">The Role of Loss Functions</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Multi-class-SVM-Loss"><span class="toc-number">6.3.1.</span> <span class="toc-text">Multi-class SVM Loss</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cross-entropy-loss"><span class="toc-number">6.4.</span> <span class="toc-text">cross-entropy loss</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Optimization-Methods-and-Regularization"><span class="toc-number">7.</span> <span class="toc-text">Optimization Methods and Regularization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent"><span class="toc-number">7.1.</span> <span class="toc-text">gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Bias-Trick"><span class="toc-number">7.2.</span> <span class="toc-text">The Bias Trick</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Stochastic-Gradient-Descent-SGD"><span class="toc-number">7.3.</span> <span class="toc-text">Stochastic Gradient Descent (SGD)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Neural-Network-Fundamentals"><span class="toc-number">8.</span> <span class="toc-text">Neural Network Fundamentals</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Neural-Network-Basics"><span class="toc-number">8.1.</span> <span class="toc-text">Neural Network Basics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#What-are-Neural-Networks"><span class="toc-number">8.2.</span> <span class="toc-text">What are Neural Networks?</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        deep learning for computer vision
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Jenkooo</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-04-22T14:13:37.571Z" itemprop="datePublished">2020-04-22</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> › <a class="category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/keras/">keras</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h2 id="What-is-deep-learning"><a href="#What-is-deep-learning" class="headerlink" title="What is deep learning"></a>What is deep learning</h2><p>总结：</p>
<p>如果一个神经网络大于2层，则可以被认为是深度学习，大于10层则是非常深度的学习</p>
<p>人工智能&gt;机器学习&gt;深度学习</p>
<h2 id="Image-Fundamentals"><a href="#Image-Fundamentals" class="headerlink" title="Image Fundamentals"></a>Image Fundamentals</h2><h3 id="什么是像素？"><a href="#什么是像素？" class="headerlink" title="什么是像素？"></a>什么是像素？</h3><p>照片是由万千像素组成的像素网格，一个像素可以认为是一个颜色。</p>
<p>所有颜色可以由三原色组成，灰度值由0-255，是最暗，255最亮</p>
<h3 id="在一个照片中，我们该怎么展示像素？"><a href="#在一个照片中，我们该怎么展示像素？" class="headerlink" title="在一个照片中，我们该怎么展示像素？"></a>在一个照片中，我们该怎么展示像素？</h3><p>想象一个照片是一个四方的网格，左上角是（0，0）往右下角移动，这个点也在增大，那么不同颜色占在不同的位置上，整体看上去，就形成了图片</p>
<h3 id="我们该怎么去接受像素用Numpy库去展示它"><a href="#我们该怎么去接受像素用Numpy库去展示它" class="headerlink" title="我们该怎么去接受像素用Numpy库去展示它?"></a>我们该怎么去接受像素用Numpy库去展示它?</h3><p>一个图片是由一个像素网格组成，一个像素又rgb三原色的值组成，当一张图像成为一个Numpy对象的时候，图片里面的像素的三原色就成了Numpy的属性。用一个三维的向量矩阵去显示三原色的值</p>
<h2 id="Image-Classification-Basic"><a href="#Image-Classification-Basic" class="headerlink" title="Image Classification Basic"></a>Image Classification Basic</h2><h3 id="什么是图片分类？"><a href="#什么是图片分类？" class="headerlink" title="什么是图片分类？"></a>什么是图片分类？</h3><p>简单来说，相当于给分类系统输入一张照片，然后经过系统处理，给出一个在系统中已经定义好了的一个标签概率，比如这个分类系统有{狗，猫，熊猫}，输入一个猫的图片，分别给出的准确概率是{5%,96%,1%}那么这个输入的图片就被认为是猫。</p>
<h3 id="深度学习的类型"><a href="#深度学习的类型" class="headerlink" title="深度学习的类型"></a>深度学习的类型</h3><p>监督学习、半监督学习、无监督学习</p>
<ul>
<li><p>监督学习：好比有一个老师带学习，学生可以借鉴前人的知识来学习。也可以比如一个邮件分析系统，分类是垃圾邮件还是非垃圾邮件，有一个数据集，里面的邮件已经被标注了哪些是垃圾邮件，哪些是正常邮件，然后交给系统去训练，学会什么样子的邮件大概率是垃圾邮件，哪些不是垃圾邮件。</p>
<p>通用的监督学习算法： <strong>Logistic Regression</strong>、<strong>Support Vector Machines (SVMs)</strong>、<strong>Random Forests</strong> 、<strong>Artifificial Neural Networks （ANN）</strong></p>
</li>
<li><p>无监督学习：则是输入的数据集中没有相关的标签，相当于自己教自己该怎么做</p>
<p>通用的无监督学习算法: <strong>Principle Component Analysis (PCA)</strong>、 <strong>k-means clustering</strong></p>
</li>
<li><p>半监督学习：输入的数据集有一半的数据是有标签的，其他的则没有标签</p>
<p>通用的半监督学习算法： <strong>label spreading</strong>、 <strong>label propagation</strong>、<strong>ladder networks</strong>、<strong>co-learning/co-training</strong></p>
</li>
</ul>
<h3 id="建立深度学习网络步骤"><a href="#建立深度学习网络步骤" class="headerlink" title="建立深度学习网络步骤"></a>建立深度学习网络步骤</h3><ol>
<li>收集初始数据集：标注图片是什么类型，但同时会产生一个问题，分类不均衡，比如{猫，狗，熊猫}中的分类系统，然后初始数据集中标注猫的有200只，狗的有2000只，熊猫的有20000，那么最后得到的结果就会不准确，最好解决这个问题的就是初始数据集标注均衡。</li>
<li>分类数据集：一个训练数据集，一个测试数据集，通常的分开比例训练集66.6%，测试集33.3%和75%<em>/</em>25%, and 90%<em>/</em>10%</li>
<li>训练神经网络：用训练数据集去训练神经网络，这个过程中，我们神经网络会从错误的分类中提高自己的准确度</li>
<li>评估神经网络准确度：训练完成后，用测试数据集去评估神经网络的准确度</li>
</ol>
<h3 id="基于特征的学习和深度学习在图片分类的不同"><a href="#基于特征的学习和深度学习在图片分类的不同" class="headerlink" title="基于特征的学习和深度学习在图片分类的不同"></a>基于特征的学习和深度学习在图片分类的不同</h3><p>基于特征的学习在深度学习网络步骤中，在第23步中，还需要加入一个特征提取的步骤，需要提取图片中的特征部分，并把它向量数字化，拿给神经网络，但是在深度学习中采用CNN算法中就不需要特征提取步骤</p>
<h2 id="Datasets-for-Image-Classification"><a href="#Datasets-for-Image-Classification" class="headerlink" title="Datasets for Image Classification"></a>Datasets for Image Classification</h2><h3 id="MNIST"><a href="#MNIST" class="headerlink" title="MNIST"></a>MNIST</h3><p>modified national institute of standards and technology，里面的数据已经被预处理过，可以用来做图片分类和机器学习研究，这个数据集的目的是正确分类数据0-9。在MNIST上训练一个神经网络，就好比其他程序设计语言的HelloWorld类型的入门程序。这也就是TensorFlow的第一个人们程序是在MNIST上进行训练数字的原因</p>
<p>MNIST包含了60000个训练图片和10000个测试图片，每张图片都是28*28像素大小，所有的图片背景都是黑色的，数字是白色的</p>
<h3 id="Animals-Dogs-Cats-Pandas"><a href="#Animals-Dogs-Cats-Pandas" class="headerlink" title="Animals: Dogs, Cats, Pandas"></a>Animals: Dogs, Cats, Pandas</h3><p>这个数据集包含了狗，猫和熊猫的分类图片各1000张，这个数据库的目的是正确分类一张图包含狗或者猫或者熊猫的图片</p>
<h3 id="CIFAR-10"><a href="#CIFAR-10" class="headerlink" title="CIFAR-10"></a>CIFAR-10</h3><p>CIFAR-10是另外一种在计算机视觉和机器学习的图像分类的标准带有标记的数据集，它包含了60000张32 * 32 * 3(RGB)图像，是一个3072维度的特征向量，正如名字一般，有10种分类，包括： <em>airplanes</em>, <em>automobiles</em>, birds, <em>cats</em>, <em>deer</em>, <em>dogs</em>, <em>frogs</em>, <em>horses</em>, <em>ships</em>, and <em>trucks</em>. </p>
<h3 id="SMILES"><a href="#SMILES" class="headerlink" title="SMILES"></a>SMILES</h3><p>SMILES数据集，正如名字一样，里面包含了很多面部有笑容和无笑容的数据集，一共有13165张，每张的尺寸都是64*64</p>
<h3 id="Kaggle-Dogs-Vs-cats"><a href="#Kaggle-Dogs-Vs-cats" class="headerlink" title="Kaggle: Dogs Vs cats"></a>Kaggle: Dogs Vs cats</h3><p>整个数据集包含了25000张猫与狗的照片，原本是用于Kaggle比赛区别猫和狗的作用</p>
<h3 id="Flowers-17"><a href="#Flowers-17" class="headerlink" title="Flowers-17"></a>Flowers-17</h3><p>整个数据集包含了17种花的照片，每种花有80张图片，用于训练预测花的种类</p>
<h3 id="CALTECH-101"><a href="#CALTECH-101" class="headerlink" title="CALTECH-101"></a>CALTECH-101</h3><p>整个数据集包含了8677张照片，里面有101种类型，可以用于机器学习和深度学习，去训练模型，更好的预测类型，其中包含了elephants, bicycles, soccer balls, and even human brains，但是也有一个问题，就是里面存在严重的种类照片数目分布不均衡，有的种类照片数严重超过其他种类照片数。用这个数据集去训练模型，准确度在35%-65%</p>
<h3 id="Tiny-ImageNet-200"><a href="#Tiny-ImageNet-200" class="headerlink" title="Tiny ImageNet 200"></a>Tiny ImageNet 200</h3><p>整个数据集包含了200个种类，每个种类有500张训练图片，50个验证图片，50个测试图片，每张照片都被预处理成了64 * 64 * 3的像素，这样使得使用者更加容易去集中于学习深度学习技术，而不是去进行计算机图片预处理工作</p>
<h3 id="Adience"><a href="#Adience" class="headerlink" title="Adience"></a>Adience</h3><p>Adience数据集是用于研究年龄和性别的认识，共26580张照片，里面包含的照片年龄范围是0-60岁，这个数据集的目的是准确的预测一个人的年龄和性别</p>
<h3 id="ImageNet"><a href="#ImageNet" class="headerlink" title="ImageNet"></a>ImageNet</h3><p>ImageNet实际上是一个项目，旨在根据定义的单词和短语集，将图像标记并分类为近22000个类别。在这个项目中，拥有超过1400万的照片，每张照片都有自己的语义词，每个语义词都有超过1000张图片。ILSVRC，图像网增强视觉认识挑战赛，goal是分类1000中不同的种类，用120万张照片去训练模型，50000张照片做验证集，100000张照片做测试集，</p>
<h3 id="Indoor-CVPR"><a href="#Indoor-CVPR" class="headerlink" title="Indoor CVPR"></a>Indoor CVPR</h3><p>这个数据集包含了需要屋内的场景的照片，包括商店，房子，休闲场所，工作室，公共场所，这个数据集的目的是训练一个模型能很好的区分这个区域是什么类型的</p>
<h3 id="Stanford-Cars"><a href="#Stanford-Cars" class="headerlink" title="Stanford Cars"></a>Stanford Cars</h3><p>包含了16185张196种类型的车子照片。</p>
<h2 id="Your-First-Image-Classifier"><a href="#Your-First-Image-Classifier" class="headerlink" title="Your First Image Classifier"></a>Your First Image Classifier</h2><p>在这里我们先讨论K-Nearest Neighbors (KNN)算法，作为第一个例子去分类图片，在这里面我们也能学到一个算法它是如果在数据中学习的，这节我们用KNN算法去识别动物图片的种类</p>
<p>在进行图片训练的时候，我们应该注意图片的尺寸，和图片的数量，在当我们把图片拿给算法训练的时候，有时候会应该电脑的内存不够或者性能不好，而导致内存溢出。所以每次在训练之前，都应该思考数据集的大小和图片尺寸问题</p>
<h3 id="K-NN-Algorithm"><a href="#K-NN-Algorithm" class="headerlink" title="K-NN Algorithm"></a>K-NN Algorithm</h3><p>工作原理是：插入的未知类型的图片去与已知的各个类型进行远近距离比较，离得最近的就是位置类型图片的类型，它也就被分类到最近的类型。KNN algorithm最邻近算法，常用于分类问题和回归问题</p>
<p>KNN算法有两个超参数：</p>
<p>1.其中一个就是k值，k值太小，比如等于1，那么它得到结果会很高效，但是受到噪声和异常数据点的影响也会提高。然而如果k太大，那么我们分类结果就会增加过于平滑分类和分类偏移的风险。</p>
<p>2：第二个就是实际测量距离。</p>
<h2 id="Parameterized-Learning"><a href="#Parameterized-Learning" class="headerlink" title="Parameterized Learning"></a>Parameterized Learning</h2><p>参数化学习：好比一个学习模型，能总结固定尺寸带有一系列参数的数据</p>
<p>参数化学习，是一个线性分类模型，是其他机器学习和深度学习的基石</p>
<p>参数化学习：是定义一个好的模型的必要的参数的过程</p>
<h3 id="An-Introduction-to-Linear-Classification"><a href="#An-Introduction-to-Linear-Classification" class="headerlink" title="An Introduction to Linear Classification"></a>An Introduction to Linear Classification</h3><p>通常来说，线性分类算法是从训练集中学习某种模式</p>
<p>参数化学习包括四个部分：</p>
<ol>
<li><p>Data：</p>
<p>​    这个部分就是我们输入的给机器学习的数据，包括数据点(照片的原始像素强度，提取的特征等)和对应的类标签，这里有一个概念： a multi-dimensional <strong>design matrix</strong>(多维设计矩阵)，比如有一个数据集里面有100个照片，都是32*32像素的，那么第xi(i&lt;0&lt;=100)行表示的就是第i张照片的rgb，然后又一个yi表示列，定义的是一个特征向量，提供了一个类标签给第xi照片</p>
</li>
<li><p>Scoring Function：</p>
<p>​    作用是：接受一个我们输入的照片，然后给这个照片映射为一个类标签。比如给一张测试照片，然后经过scoring function 可以简称F函数，然后输出返回一个预测的类标签</p>
</li>
<li><p>Loss Function：</p>
<p>​    损失函数是数字化了我们预测的类标签，即损失函数值越低，则我们分类的精准度越高</p>
</li>
<li><p>Weights and Biases</p>
<p>​    weight matrix权重矩阵，简称w，bias vector 偏移向量简称b，我们可以寻找一系列最优化的方法去最小化我们的Loss Function，去提高我们分类预测的精准度。</p>
<p>​    例子，对于32* 32 * 3的一个固定尺寸的cats，dogs，pandas数据集，对于权重矩阵w：<strong>有3行(每一个就是一个类标签)，有3072列(每一张张片对应的像素32 X 32 X 3)</strong></p>
</li>
</ol>
<h3 id="Linear-Classification-From-Images-to-Labels"><a href="#Linear-Classification-From-Images-to-Labels" class="headerlink" title="Linear Classification: From Images to Labels"></a>Linear Classification: From Images to Labels</h3><p>在线性分类过程中，是如何从一个图片映射到类标签的？</p>
<p>以cats，dogs，pandas数据集为例子，一共有3000张照片，每张照片都是32 * 32固定像素，用rgb值去表示，在这个数据集中D=32 X 32 X 3=3072 不同的值，类标签一共有3种，k=3，dog，cat，panda，对于这么多的变化的值，我们定义f去从照片映射到类标签分数，这里我们定义一个简单的线性映射函数<br>$$<br>f(xi,W,b) = W xi +b<br>$$<br>我们假定i张照片xi，表示成一个独立的列向量[D * 1]，权重矩阵w是一个[K * D]矩阵，最终偏移向量b是一[K * 1]</p>
<p>的矩阵</p>
<p>参数化学习和线性分类的优点：</p>
<p>1.一旦我们训练完模型，我们就不用去关心输入的数据，而是更加关心权重矩阵w和偏移向量b</p>
<p>2.分类新的测试集速度十分快</p>
<p>具体简单实现f函数的分类代码，在C8 python包中</p>
<h3 id="The-Role-of-Loss-Functions"><a href="#The-Role-of-Loss-Functions" class="headerlink" title="The Role of Loss Functions"></a>The Role of Loss Functions</h3><p>Loss Function：损失函数</p>
<p>Loss score值越低，则对结果集里面的预测值就越高</p>
<h4 id="Multi-class-SVM-Loss"><a href="#Multi-class-SVM-Loss" class="headerlink" title="Multi-class SVM Loss"></a>Multi-class SVM Loss</h4><p>多类SVM损失是由SVM优化得来，它本身是用来测评一个f映射函数的好与坏。比如现在我们已经有了一个简单的映射f函数<br>$$<br>f(xi,W,b) = W xi +b<br>$$<br>但是我们怎么知道这个f函数对预测的好与坏？就是通过Multi-class SVM Loss的值来体现，越小，则f函数的预测越好。</p>
<h3 id="cross-entropy-loss"><a href="#cross-entropy-loss" class="headerlink" title="cross-entropy loss"></a>cross-entropy loss</h3><p>交叉熵损失，也是另外一种比较流行的损失函数</p>
<h2 id="Optimization-Methods-and-Regularization"><a href="#Optimization-Methods-and-Regularization" class="headerlink" title="Optimization Methods and Regularization"></a>Optimization Methods and Regularization</h2><p>优化算法是强大的神经网络的核心动力，能够促使他们从数据中学习参数</p>
<h3 id="gradient-descent"><a href="#gradient-descent" class="headerlink" title="gradient descent"></a>gradient descent</h3><p>梯度下降是优化算法中很流行的一种算法，梯度下降算法有很多种变化，但是它的核心思想却是一样的。</p>
<p>1.迭代评价你的参数</p>
<p>2.计算损失值</p>
<p>3.在这个方向取一小步，最小化损失值</p>
<p>梯度下降就是一种迭代优化算法，每一个迭代就会降低一点损失值，去提高预测准确性，但是我们在实际的问题中，我们并不知道，哪里是局部最低值，哪里是全局最低值，可能损失表面是一个多维的模块，需要一点一点的移动，调试，才能寻找到局部最低值或者全局最低值。</p>
<p>在先进很多算法中，可能我们在损失函数的局部最小值都没有达到，但是在实际的运用中，这个小的损失函数值，已经够用了</p>
<h3 id="The-Bias-Trick"><a href="#The-Bias-Trick" class="headerlink" title="The Bias Trick"></a>The Bias Trick</h3><p>The Bias Trick 是用来把权重矩阵w和偏移向量b联系在一起的关键核心，为了联系这两者的关系，我们额外增加了一维度给输入的数据X，要么加在第一维度，要么加在最后一个维度，数值是1。这样的话我们的scoring function就变成了这样的形式<br>$$<br>f(xi,W) = W xi<br>$$</p>
<h3 id="Stochastic-Gradient-Descent-SGD"><a href="#Stochastic-Gradient-Descent-SGD" class="headerlink" title="Stochastic Gradient Descent (SGD)"></a>Stochastic Gradient Descent (SGD)</h3><p>是一种标准梯度下降的升级，这样可以更好的对权重矩阵更新</p>
<h2 id="Neural-Network-Fundamentals"><a href="#Neural-Network-Fundamentals" class="headerlink" title="Neural Network Fundamentals"></a>Neural Network Fundamentals</h2><p> <em>backpropagation algorithm</em> 反向传播算法，在Keras里面已经有了内置反向传播算法，但是我们还是希望能够手动的实现</p>
<p>建立一个神经网络需要四个重要部分</p>
<h3 id="Neural-Network-Basics"><a href="#Neural-Network-Basics" class="headerlink" title="Neural Network Basics"></a>Neural Network Basics</h3><p> Convolutional Neural Networks 卷积神经网络</p>
<p>人工神经网络与生物神经网络的关系？</p>
<p> Perceptron algorithm 感知器算法？</p>
<p>反向传播算法是怎样被用来高效训练多层神经网络？</p>
<p>怎么用Keras库来训练神经网络？</p>
<p>这章目标是：理解神经网络，能够为理解卷积神经网络打下坚实基础</p>
<h3 id="What-are-Neural-Networks"><a href="#What-are-Neural-Networks" class="headerlink" title="What are Neural Networks?"></a>What are Neural Networks?</h3><p>神经网络又很多很多的神经细胞组成，每一个神经细胞都连接着上千个相同的神经细胞，各个之间传递信息，计算机则就模拟人体内的这种神经传递方式，形成了人工神经网络。</p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-is-deep-learning"><span class="toc-number">1.</span> <span class="toc-text">What is deep learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Image-Fundamentals"><span class="toc-number">2.</span> <span class="toc-text">Image Fundamentals</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是像素？"><span class="toc-number">2.1.</span> <span class="toc-text">什么是像素？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#在一个照片中，我们该怎么展示像素？"><span class="toc-number">2.2.</span> <span class="toc-text">在一个照片中，我们该怎么展示像素？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#我们该怎么去接受像素用Numpy库去展示它"><span class="toc-number">2.3.</span> <span class="toc-text">我们该怎么去接受像素用Numpy库去展示它?</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Image-Classification-Basic"><span class="toc-number">3.</span> <span class="toc-text">Image Classification Basic</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是图片分类？"><span class="toc-number">3.1.</span> <span class="toc-text">什么是图片分类？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#深度学习的类型"><span class="toc-number">3.2.</span> <span class="toc-text">深度学习的类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#建立深度学习网络步骤"><span class="toc-number">3.3.</span> <span class="toc-text">建立深度学习网络步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基于特征的学习和深度学习在图片分类的不同"><span class="toc-number">3.4.</span> <span class="toc-text">基于特征的学习和深度学习在图片分类的不同</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Datasets-for-Image-Classification"><span class="toc-number">4.</span> <span class="toc-text">Datasets for Image Classification</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MNIST"><span class="toc-number">4.1.</span> <span class="toc-text">MNIST</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Animals-Dogs-Cats-Pandas"><span class="toc-number">4.2.</span> <span class="toc-text">Animals: Dogs, Cats, Pandas</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CIFAR-10"><span class="toc-number">4.3.</span> <span class="toc-text">CIFAR-10</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SMILES"><span class="toc-number">4.4.</span> <span class="toc-text">SMILES</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kaggle-Dogs-Vs-cats"><span class="toc-number">4.5.</span> <span class="toc-text">Kaggle: Dogs Vs cats</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flowers-17"><span class="toc-number">4.6.</span> <span class="toc-text">Flowers-17</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CALTECH-101"><span class="toc-number">4.7.</span> <span class="toc-text">CALTECH-101</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tiny-ImageNet-200"><span class="toc-number">4.8.</span> <span class="toc-text">Tiny ImageNet 200</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Adience"><span class="toc-number">4.9.</span> <span class="toc-text">Adience</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ImageNet"><span class="toc-number">4.10.</span> <span class="toc-text">ImageNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Indoor-CVPR"><span class="toc-number">4.11.</span> <span class="toc-text">Indoor CVPR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Stanford-Cars"><span class="toc-number">4.12.</span> <span class="toc-text">Stanford Cars</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Your-First-Image-Classifier"><span class="toc-number">5.</span> <span class="toc-text">Your First Image Classifier</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K-NN-Algorithm"><span class="toc-number">5.1.</span> <span class="toc-text">K-NN Algorithm</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Parameterized-Learning"><span class="toc-number">6.</span> <span class="toc-text">Parameterized Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#An-Introduction-to-Linear-Classification"><span class="toc-number">6.1.</span> <span class="toc-text">An Introduction to Linear Classification</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Linear-Classification-From-Images-to-Labels"><span class="toc-number">6.2.</span> <span class="toc-text">Linear Classification: From Images to Labels</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Role-of-Loss-Functions"><span class="toc-number">6.3.</span> <span class="toc-text">The Role of Loss Functions</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Multi-class-SVM-Loss"><span class="toc-number">6.3.1.</span> <span class="toc-text">Multi-class SVM Loss</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cross-entropy-loss"><span class="toc-number">6.4.</span> <span class="toc-text">cross-entropy loss</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Optimization-Methods-and-Regularization"><span class="toc-number">7.</span> <span class="toc-text">Optimization Methods and Regularization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent"><span class="toc-number">7.1.</span> <span class="toc-text">gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Bias-Trick"><span class="toc-number">7.2.</span> <span class="toc-text">The Bias Trick</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Stochastic-Gradient-Descent-SGD"><span class="toc-number">7.3.</span> <span class="toc-text">Stochastic Gradient Descent (SGD)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Neural-Network-Fundamentals"><span class="toc-number">8.</span> <span class="toc-text">Neural Network Fundamentals</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Neural-Network-Basics"><span class="toc-number">8.1.</span> <span class="toc-text">Neural Network Basics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#What-are-Neural-Networks"><span class="toc-number">8.2.</span> <span class="toc-text">What are Neural Networks?</span></a></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/" target="_blank" rel="noopener"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&text=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&title=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&is_video=false&description=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=deep learning for computer vision&body=Check out this article: https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&title=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&title=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&title=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&title=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&name=deep learning for computer vision&description=" target="_blank" rel="noopener"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://news.ycombinator.com/submitlink?u=https://hardingyang.github.io/2020/04/22/How-to-get-started-with-keras-deep-learning/&t=deep learning for computer vision" target="_blank" rel="noopener"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2019-2020
    Jenkooo
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->

<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">


<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">


    <!-- jquery -->

<script src="/lib/jquery/jquery.min.js"></script>


<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

  
<script src="/lib/clipboard/clipboard.min.js"></script>

  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?3611d43b4ebdcc59c13f6739c83aac46";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->


</body>
</html>
